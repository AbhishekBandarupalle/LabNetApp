############################################################################
#
# SCENARIO 5: Run Apache with persistent volumes
#
############################################################################

GOAL:
This scenario can be used to demonstrate how a webserver can benefit from persistent volumes
The creation of the webserver will be done is several steps:
- creation of the PVC
- creation of the Apache webserver
- creation of the service

The files used in the scenario are all in the directory: https://github.com/YvosOnTheHub/LabNetApp/tree/master/Kubernetes/Scenarios/Scenario5

Prerequisites:
- Trident is already configured
- a storage class "storage-class-nas" must already be configured


A. Let's start by creating a persistent volume that will be used by Apache

[root@rhel3 apache]# kubectl create -f pvc-apache.yaml
persistentvolumeclaim "pvc-apache" created

[root@rhel3 apache]# kubectl get pvc
NAME         STATUS    VOLUME                     CAPACITY     ACCESS MODES   STORAGECLASS        AGE
pvc-apache   Bound     default-pvc-apache-ea4c2   1073741824   RWO            storage-class-nas   22s

[root@rhel3 mnt]# kubectl get pv
NAME                       CAPACITY     ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                STORAGECLASS        REASON    AGE
default-pvc-apache-ea4c2   1073741824   RWO            Delete           Bound     default/pvc-apache   storage-class-nas             7m



B. Let's copy some content in this folder (this is a shortcut as the focus of this lab is more the application itself...)

the shortcut consists in mounting the PV directly on the host & copy the file you will find in the folder:
https://github.com/YvosOnTheHub/LabNetApp/tree/master/Kubernetes/Scenarios/Scenario5/Apache

The path of the volume to mount can be found with the command "kubectl describe":

[root@rhel3 mnt]# kubectl describe pv default-pvc-apache-ea4c2 | grep Server -C 1
    Type:      NFS (an NFS mount that lasts the lifetime of a pod)
    Server:    192.168.0.135
    Path:      /trident_default_pvc_apache_ea4c2
	
You could choose to create our own content or modify what is in the data directory.
If you are going to use the content provided in this lab, you will need to rename one of the index files into index.php
	

	
C. We will now create the Apache application through a deployment.

A deployment is a way to create an application, or if you like a pod with extra metadata, such as the number of replicas.
The file we are using will also describe how to mount the Persistent Volumes we have just created.
In our example, we specified that we want 2 replicas of the POD running at any time in the cluster.

[root@rhel3 apache]# kubectl create -f deployment-apache.yaml
deployment.apps "apache" created

[root@rhel3 apache]# kubectl get deployment -o wide
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES           SELECTOR
apache    2         2         2            2           1m        apache       php:7.0-apache   app=apache

[root@rhel3 apache]# kubectl get pods -o wide
NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
apache-7cb9dd4bbd-dvsr9   1/1       Running   0          1m        10.244.2.14   rhel1
apache-7cb9dd4bbd-snwr4   1/1       Running   0          1m        10.244.1.26   rhel2

By using the "kubectl describe" command on both pods, you can see that they indeed do mount the PVC created earlier.



D. How to access this apache server ?!

Creating an application or a deployment does not mean you can access it right away !
You still need to define how you are going to access your pod, by creating services, which in short defines the end-points to reach your application.

Services' rules differ when you are in the Public Cloud from when you are using a cluster on your own server.
Here are some good reads about this:
https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0
https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/

For this exercise, I used the NodePort service, which will basically define a port (30080 for instance) that is going to be exposed on every host.
You can there reach the application on this port from any host on the cluster.

[root@rhel3 apache]# kubectl create -f svc-apache.yaml
service "apache" created

[root@rhel3 apache]# kubectl get svc apache -o wide
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE       SELECTOR
apache       NodePort    10.105.133.162   <none>        80:30080/TCP   8s        app=apache



E. Try it out !

Open you favorite browser and connect to one of the cluster host on the 30080 port, and see the result !



F. Bonus1. Play around with replicas

We have defined in the Apache Deployment to have 2 pods running at all time. Usually, this would be coupled with a Load Balancer in order not to route every request to one single container.

[root@rhel3 apache]# kubectl get pods -o wide
NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
apache-7cb9dd4bbd-dvsr9   1/1       Running   0          5h        10.244.2.14   rhel1
apache-7cb9dd4bbd-snwr4   1/1       Running   0          5h        10.244.1.26   rhel2

[root@rhel3 apache]# kubectl get deployment -o wide
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES           SELECTOR
apache    2         2         2            2           5h        apache       php:7.0-apache   app=apache

Let's see what happens if we kill one of the Apache Pods.
In my test I will kill the pod that is been accessed in the browser.

[root@rhel3 apache]# kubectl delete pod apache-7cb9dd4bbd-dvsr9
pod "apache-7cb9dd4bbd-dvsr9" deleted

[root@rhel3 apache]# kubectl get deployment -o wide
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES           SELECTOR
apache    2         2         2            1           5h        apache       php:7.0-apache   app=apache

[root@rhel3 apache]# kubectl get deployment -o wide
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES           SELECTOR
apache    2         2         2            2           5h        apache       php:7.0-apache   app=apache

We are back to a stable environment.

[root@rhel3 apache]# kubectl get pods -o wide
NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
apache-7cb9dd4bbd-547nr   1/1       Running   0          12s       10.244.2.15   rhel1
apache-7cb9dd4bbd-snwr4   1/1       Running   0          5h        10.244.1.26   rhel2

Result: we can still access our web server in our browser, however, we are reading data from another container.

What happends if we reduce the number of replicas to 1?

[root@rhel3 apache]# kubectl scale deploy apache --replicas=1
deployment.extensions "apache" scaled

[root@rhel3 apache]# kubectl get deployment -o wide
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES           SELECTOR
apache    1         1         1            1           5h        apache       php:7.0-apache   app=apache

[root@rhel3 apache]# kubectl get pods -o wide
NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
apache-7cb9dd4bbd-snwr4   1/1       Running   0          5h        10.244.1.26   rhel2

There is only one container running for our Apache pod.
What if we kill it ?

[root@rhel3 apache]# kubectl delete pod apache-7cb9dd4bbd-snwr4
pod "apache-7cb9dd4bbd-snwr4" deleted

[root@rhel3 apache]# kubectl get deployment -o wide
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES           SELECTOR
apache    1         1         1            1           5h        apache       php:7.0-apache   app=apache

[root@rhel3 apache]# kubectl get pods -o wide
NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
apache-7cb9dd4bbd-xzj5q   1/1       Running   0          17s       10.244.2.16   rhel1

As expected, Kubernetes will restart another POD with the same configuration, or in other words, the application will still work !
Since the data is outside of the container, it allows the pod to start quickly & the data is totally secured by the underlying infrastructure
