############################################################################
#
# SCENARIO 4: Test new features released in Trident 18.10
#
############################################################################

GOAL:
This scenario can be used to demonstrate 3 new features introduces with Trident 18.10:
- limitVolumeSize
- snapshotReserve
- LimitAggregateUsage

The YAML files used in the scenario are all in the directory: https://github.com/YvosOnTheHub/LabNetApp/tree/master/Kubernetes/Scenarios/Scenario4


A. Create a backend file for this exercice with "limitVolumeSize" & "snapshotReserve" parameters
- limitVolumeSize = 20GiB
- SnapshotReserve = 20%

In the following example, I used the file backend-news-vsadmin-18.10.json .

# tridentctl create backend -n trident -f backend-news-vsadmin-18.10.json
+---------------------------+----------------+--------+---------+
|           NAME            | STORAGE DRIVER | ONLINE | VOLUMES |
+---------------------------+----------------+--------+---------+
| Backend_news_1810_vsadmin | ontap-nas      | true   |       0 |
+---------------------------+----------------+--------+---------+


B. Create two PVC, one of 10GiB & one of of 20GiB

In the following example, I used the file pvc-10Gi-1.yaml & pvc-20Gi-1.yaml, which request respectively a volume of 10GiB & a volume of 20GiB.

[root@rhel3 Kubernetes]# kubectl create -f pvc-10Gi-1.yaml
persistentvolumeclaim "10gb-1" created

[root@rhel3 Kubernetes]# kubectl create -f pvc-20Gi-1.yaml
persistentvolumeclaim "20gb-1" created

Let's look at the status of these 2 volumes

[root@rhel3 Kubernetes]# kubectl get pvc
NAME      STATUS    VOLUME                 CAPACITY   ACCESS MODES   STORAGECLASS        AGE
10gb-1    Bound     default-10gb-1-e1cd0   10Gi       RWO            storage-class-nas   4s
20gb-1    Pending 


C. limitVolumeSize Validation

Notice in the 'kubectl get pvc' command that the 20GiB PVC is still in 'pending' state.
Let's look at the details of this PVC, which includes some. logs

[root@rhel3 Kubernetes]# kubectl describe pvc 20gb-1
Name:          20gb-1
Namespace:     default
StorageClass:  storage-class-nas
Status:        Pending
Volume:
Labels:        <none>
Annotations:   volume.beta.kubernetes.io/storage-class=storage-class-nas
               volume.beta.kubernetes.io/storage-provisioner=netapp.io/trident
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:
Access Modes:
Events:
  Type    Reason                Age                From                         Message
  ----    ------                ----               ----                         -------
  Normal  ProvisioningFailed    18s (x2 over 19s)  netapp.io/trident            encountered error(s) in creating the volume: [Failed to create volume default-20gb-1-c5593 on storage pool aggr2 from backend Backend_news_1810_vsadmin: requested size: 21474836480 > the size limit: 10737418240], [Failed to create volume default-20gb-1-c5593 on storage pool aggr1 from backend Backend_news_1810_vsadmin: requested size: 21474836480 > the size limit: 10737418240]
  Normal  ProvisioningFailed    12s                netapp.io/trident            encountered error(s) in creating the volume: [Failed to create volume default-20gb-1-c5593 on storage pool aggr1 from backend Backend_news_1810_vsadmin: requested size: 21474836480 > the size limit: 10737418240], [Failed to create volume default-20gb-1-c5593 on storage pool aggr2 from backend Backend_news_1810_vsadmin: requested size: 21474836480 > the size limit: 10737418240]
  Normal  ExternalProvisioning  5s (x3 over 19s)   persistentvolume-controller  waiting for a volume to be created, either by external provisioner "netapp.io/trident" or manually created by system administrator

=> the volume cannot be created, and an error is raised.


D. SnapshotReserve Validation

Let's connect to the ONTAP platform to validate the snapshot reserve for the 10GiB volume

cluster1::> vol show k8s_nas_1810_default_10gb_1_e1cd0 -fields percent-snapshot-space
vserver volume                            percent-snapshot-space
------- --------------------------------- ----------------------
svm1    k8s_nas_1810_default_10gb_1_e1cd0 20%

=> the parameter has been set accordingly.


E. Create a backend file for this exercice with "LimitAggregateUsage"
- LimitAggregateUsage = 50%

In the following example, I used the file backend-news-admin-18.10.json .
For this exercise, the previous elements need to be cleaned up.

# tridentctl create backend -n trident -f backend-news-admin-18.10.json
+---------------------------+----------------+--------+---------+
|           NAME            | STORAGE DRIVER | ONLINE | VOLUMES |
+---------------------------+----------------+--------+---------+
| Backend_news_1810_admin   | ontap-nas      | true   |       0 |
+---------------------------+----------------+--------+---------+

=> notice that this feature requires to be used with the cluster admin user, not the SVM admin
=> also, to make this demo succesful, thick provisioning must be used.


F. Create two PVC, one of 10GiB & one of of 20GiB

In the following example, I used the file pvc-10Gi-1.yaml & pvc-20Gi-1.yaml, which request respectively a volume of 10GiB & a volume of 20GiB.

# kubectl create -f pvc-10Gi-1.yaml
persistentvolumeclaim "10gb-1" created

# kubectl get pvc
NAME      STATUS    VOLUME                 CAPACITY   ACCESS MODES   STORAGECLASS        AGE
10gb-1    Bound     default-10gb-1-1d5a2   10Gi       RWO            storage-class-nas   5s

# kubectl create -f pvc-20Gi-1.yaml
persistentvolumeclaim "20gb-1" created

# kubectl get pvc
NAME      STATUS    VOLUME                 CAPACITY   ACCESS MODES   STORAGECLASS        AGE
10gb-1    Bound     default-10gb-1-1d5a2   10Gi       RWO            storage-class-nas   1m
20gb-1    Pending                                                    storage-class-nas   2s


G. limitVolumeSize Validation

Notice in the 'kubectl get pvc' command that the 20GiB PVC is still in 'pending' state.
Let's look at the details of this PVC, which includes some. logs

# kubectl describe pvc 20gb-1
Name:          20gb-1
Namespace:     default
StorageClass:  storage-class-nas
Status:        Pending
Volume:
Labels:        <none>
Annotations:   volume.beta.kubernetes.io/storage-class=storage-class-nas
               volume.beta.kubernetes.io/storage-provisioner=netapp.io/trident
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:
Access Modes:
Events:
  Type    Reason                Age               From                         Message
  ----    ------                ----              ----                         -------
  Normal  ProvisioningFailed    23s               netapp.io/trident            encountered error(s) in creating the volume: [Failed to create volume default-20gb-1-40637 on storage pool aggr2 from backend Backend_news_1810_admin: aggregate usage of 52.91 % would exceed the limit of 50.00 %], [Failed to create volume default-20gb-1-40637 on storage pool aggr1 from backend Backend_news_1810_admin: aggregate usage of 72.47 % would exceed the limit of 50.00 %]
  Normal  ProvisioningFailed    23s               netapp.io/trident            encountered error(s) in creating the volume: [Failed to create volume default-20gb-1-40637 on storage pool aggr1 from backend Backend_news_1810_admin: aggregate usage of 72.47 % would exceed the limit of 50.00 %], [Failed to create volume default-20gb-1-40637 on storage pool aggr2 from backend Backend_news_1810_admin: aggregate usage of 52.91 % would exceed the limit of 50.00 %]
  Normal  ExternalProvisioning  0s (x4 over 23s)  persistentvolume-controller  waiting for a volume to be created, either by external provisioner "netapp.io/trident" or manually created by system administrator

=> the volume cannot be created, and an error is raised.
